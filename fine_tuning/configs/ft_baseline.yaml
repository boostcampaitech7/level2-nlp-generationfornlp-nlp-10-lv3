# seed
seed: 
  42

# wandb
project:
  "Fintuning"
sub_project:
  "test"

# data
data_pathL:
  "/data/ephemeral/home/data/v1/fine_tuning"
output_path:
  "../saved/outputs/test.csv"

# model
do_train:
  True
ft_model_path_or_name:
  "LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct"

use_lora: True
lora_rank: 6
lora_alpha: 8
lora_target_modules:
  - "q_proj"
  - "k_proj"
lora_dropout: 0.1
lora_bias: "none"
lora_task_type: "CAUSAL_LM"

steps: 20
save_total_limit: 2
per_device_train_batch_size: 1
gradient_accumulation_steps: 4
num_train_epochs: 10
lr_scheduler_type: "cosine"
learning_rate: 2e-5
weight_decay: 0.01