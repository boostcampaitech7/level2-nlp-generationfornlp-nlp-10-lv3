# wandb
project:
  "LeeJeonge"
sub_project:
  "LLaMA_32_finetuning_CoT"

# data path
data_dir:
  "./data" 
train_path:
  "v0.1.6/train.csv"
val_path:
  "v0.1.6/val.csv"
output_file:
  "inference_results.csv"

# dataset
max_length:
  2048

# data collector
response_template: # Model이 답할 부분에 대한 템플릿 시작
  "[|assistant|]"

# tokenizer
padding_side:
  'right'

# model
train_model_path_or_name: 
  "LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct"
test_model_path_or_name:
  "LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct/"

# SFT
num_train_epochs: 3
learning_rate: 0.00001
weight_decay: 0.01
logging_steps: 100
save_total_limit : 2

# LoRa
rank: 4
lora_alpha: 16
lora_dropout : 0.05
target_modules: 
  - "q_proj"  
  - "k_proj"
bias : "none"
task_type : "CAUSAL_LM"

# prompt
PROMPT_NO_QUESTION_PLUS: >
  1. 지문을 읽고 핵심 내용을 요약합니다.
  2. 질문을 분석하여 무엇을 묻는지 파악합니다.
  3. 선택지를 하나씩 평가하고, 지문과 질문과 가장 관련이 있는 선택지를 결정합니다.
  4. 선택지를 결정한 이유를 설명하고 정답을 출력하세요.

  지문:
  {paragraph}

  질문:
  {question}

  선택지:
  {choices}

  1, 2, 3, 4, 5 중에 하나를 정답으로 고르세요.
  이유:
  정답:

PROMPT_QUESTION_PLUS: >
  1. 지문을 읽고 핵심 내용을 요약합니다.
  2. 질문을 분석하여 무엇을 묻는지 파악합니다.
  3. 선택지를 하나씩 평가하고, 지문과 질문과 가장 관련이 있는 선택지를 결정합니다.
  4. 선택지를 결정한 이유를 설명하고 정답을 출력하세요.

  지문:
  {paragraph}

  질문:
  {question}

  <보기>:
  {question_plus}

  선택지:
  {choices}

  1, 2, 3, 4, 5 중에 하나를 정답으로 고르세요.
  이유:
  정답:

chat_template: null