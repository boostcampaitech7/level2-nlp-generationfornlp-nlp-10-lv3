# wandb
project: 'GenerationforNLP'
sub_project: 'Qwen2_7B_finetuning_CoT'

# data path
data_dir: '/data/ephemeral/home/gyeom/level2-nlp-generationfornlp-nlp-10-lv3/data'
train_path: 'textbook_plus_agmentation.csv'
val_path: 'val_v0.1.6.csv'
output_file: 'inference_results.csv'

# seed
seed: 42

# dataset
max_length: 2048

# data collector
response_template: '<|im_start|>assistant'

# tokenizer
padding_side: 'right'

# model
train_model_path_or_name: 'maywell/Qwen2-7B-Multilingual-RP'
test_model_path_or_name: '/data/ephemeral/home/gyeom/level2-nlp-generationfornlp-nlp-10-lv3/saved/models/maywell/Qwen2-7B-Multilingual-RP/checkpoint-12200/'

# SFT
num_train_epochs: 5
learning_rate: 0.00001
weight_decay: 0.01
logging_steps: 1
save_total_limit: 3

# LoRa
rank: 16
lora_alpha: 16
lora_dropout: 0.05
target_modules:
  - 'q_proj'
  - 'k_proj'

bias: 'none'
task_type: 'CAUSAL_LM'

# prompt
PROMPT_NO_QUESTION_PLUS: >
  <|im_start|>human
  지문을 읽고 핵심 내용을 요약합니다.
  질문을 분석하여 무엇을 묻는지 파악합니다.
  선택지를 하나씩 평가하고, 지문과 질문과 가장 관련이 있는 선택지를 결정합니다.
  선택지를 결정한 이유를 설명하고 정답을 출력하세요.

  지문:
  {paragraph}

  질문:
  {question}

  선택지:
  {choices}

  1, 2, 3, 4, 5 중에 하나를 정답으로 고르세요.
  <|im_end|>
  <|im_start|>assistant
  지문의 핵심 내용을 요약하겠습니다.

  질문 분석:

  선택지 평가:

  이유:

  정답: 
  <|im_end|>

PROMPT_QUESTION_PLUS: >
  <|im_start|>human
  지문을 읽고 핵심 내용을 요약합니다.
  질문을 분석하여 무엇을 묻는지 파악합니다.
  선택지를 하나씩 평가하고, 지문과 질문과 가장 관련이 있는 선택지를 결정합니다.
  선택지를 결정한 이유를 설명하고 정답을 출력하세요.

  지문:
  {paragraph}

  질문:
  {question}

  <보기>:
  {question_plus}

  선택지:
  {choices}

  1, 2, 3, 4, 5 중에 하나를 정답으로 고르세요.
  <|im_end|>
  <|im_start|>assistant
  지문의 핵심 내용을 요약하겠습니다.

  질문 분석:

  선택지 평가:

  이유:

  정답: 
  <|im_end|>

chat_template: '{% for message in messages %}{{"<|im_start|>" + message["role"] + "\n" + message["content"]}}{% if not loop.last or (loop.last and message["role"] != "assistant") %}{{"<|im_end|>\n"}}{% endif %}{% endfor %}{% if add_generation_prompt and messages[-1]["role"] != "assistant" %}{{ "<|im_start|>assistant\n" }}{% endif %}'
